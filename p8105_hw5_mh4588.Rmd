---
title: "Assignment 5"
author: "Maggie Hsu"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)

set.seed(8105) #set seed
```
# Problem 1
```{r problem 1 - function}
#Let integers 1-365 represent dates from January 1st to December 31st (no leap days)
bday_matches <- function(n) { #where n is the number of people in the group
  birthdays <- sample(1:365,n,replace = TRUE)
  result = (sum(duplicated(birthdays)) > 0) #since true is interpreted as 1, if there is a duplicate (or true) present in the birthdays vector, the sum will be greater than 0
  result
} 
```


Next, run this function 10000 times for each group size between 2 and 50. For each group size, compute the probability that at least two people in the group will share a birthday by averaging across the 10000 simulation runs. 

```{r problem 1 - group simulation}
birthday_output = 
  expand_grid(
    group_size = c(2:50), #group sizes between 2-50
    iter = 1:10000 #iterate 10,000 times
  ) |> 
  mutate(
    birthday_output = map(group_size, bday_matches)
  ) |> 
  unnest(birthday_output)
```

```{r problem 1 - plot}
#Compute the probability that there are two people sharing a birthday
shared_prob <- birthday_output |> 
  group_by(group_size) |> 
  summarize(
    probability = mean(sum(birthday_output)/10000)
  ) 

#Plot the relationship between the number of people in a group and two people within the group sharing a birthday
shared_prob |> 
  ggplot(aes(x = group_size, y=probability)) + #the vec? 
  geom_point() +
  geom_smooth(color = "red")
                          
```
# Problem 2



```{r problem 2}
#Initialize elements
datasets = vector("list", length = 5000)
mu = 0

t_test_sim = function(mu) {
for (i in 1:5000){
  datasets[[i]] = rnorm(n=30, mean = mu, sd=5) #Generate datasets
  t_test = broom::tidy(t.test(datasets[[i]], mu=0, conf.level=0.95)) #t-test dataset against mu=0 at a 0.95 confidence level
  tibble(
    mu_hat = t_test[1], #Extract mu-hat from the t-test summary
    p_value = t_test[3] #Extract the p-value from the t-test
  )
}
}

#repeat for mu=0 and 1-6
sim_results_df = 
  expand_grid(
    mu_range = c(0:6),
    iter = 1:5000
  ) |> 
  mutate(
    sim_results = map(mu_range, t_test_sim)
  ) |> 
  unnest(sim_results)

```
```{r plotting}

```

```{r problem 3}
homicide <- read_csv("./homicide-data.csv") #Import dataset
homicide |>
  mutate(city_state = paste(city,state, sep=', ')) #establish city,state variable

#summarize within cities to obtain the total number of homicides and the number of unsolved homicides (those for which the disposition is “Closed without arrest” or “Open/No arrest”).
```